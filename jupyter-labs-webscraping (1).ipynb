{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Space X  Falcon 9 First Stage Landing Prediction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping Falcon 9 and Falcon Heavy Launches Records from Wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **40** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will be performing web scraping to collect Falcon 9 historical launch records from a Wikipedia page titled `List of Falcon 9 and Falcon Heavy launches`\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_1_L2/images/Falcon9_rocket_family.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falcon 9 first stage will land successfully\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/landing_1.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several examples of an unsuccessful landing are shown here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/crash.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, the launch records are stored in a HTML table shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_1_L2/images/falcon9-launches-wiki.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Objectives\n",
    "Web scrap Falcon 9 launch records with `BeautifulSoup`: \n",
    "- Extract a Falcon 9 launch records HTML table from Wikipedia\n",
    "- Parse the table and convert it into a Pandas data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import required packages for this lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4\n",
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we will provide some helper functions for you to process web scraped HTML table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def date_time(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the data and time from the HTML  table cell\n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    return [data_time.strip() for data_time in list(table_cells.strings)][0:2]\n",
    "\n",
    "def booster_version(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the booster version from the HTML  table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    out=''.join([booster_version for i,booster_version in enumerate( table_cells.strings) if i%2==0][0:-1])\n",
    "    return out\n",
    "\n",
    "def landing_status(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    out=[i for i in table_cells.strings][0]\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_mass(table_cells):\n",
    "    mass=unicodedata.normalize(\"NFKD\", table_cells.text).strip()\n",
    "    if mass:\n",
    "        mass.find(\"kg\")\n",
    "        new_mass=mass[0:mass.find(\"kg\")+2]\n",
    "    else:\n",
    "        new_mass=0\n",
    "    return new_mass\n",
    "\n",
    "\n",
    "def extract_column_from_header(row):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    if (row.br):\n",
    "        row.br.extract()\n",
    "    if row.a:\n",
    "        row.a.extract()\n",
    "    if row.sup:\n",
    "        row.sup.extract()\n",
    "        \n",
    "    colunm_name = ' '.join(row.contents)\n",
    "    \n",
    "    # Filter the digit and empty names\n",
    "    if not(colunm_name.strip().isdigit()):\n",
    "        colunm_name = colunm_name.strip()\n",
    "        return colunm_name    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the lab tasks consistent, you will be asked to scrape the data from a snapshot of the  `List of Falcon 9 and Falcon Heavy launches` Wikipage updated on\n",
    "`9th June 2021`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, request the HTML page from the above URL and get a `response` object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1: Request the Falcon9 Launch Wiki page from its URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's perform an HTTP GET method to request the Falcon9 Launch HTML page, as an HTTP response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solicitud HTTP exitosa\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la página de Wikipedia de Falcon 9\n",
    "static_url = \"https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches\"\n",
    "\n",
    "# Realizar la solicitud HTTP GET\n",
    "response = requests.get(static_url)\n",
    "\n",
    "# Verificar si la solicitud fue exitosa (código 200)\n",
    "if response.status_code == 200:\n",
    "    print(\"Solicitud HTTP exitosa\")\n",
    "else:\n",
    "    print(\"Error en la solicitud HTTP:\", response.status_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `BeautifulSoup` object from the HTML `response`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use BeautifulSoup() to create a BeautifulSoup object from a response text content\n",
    "response = requests.get(static_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the page title to verify if the `BeautifulSoup` object was created properly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>List of Falcon 9 and Falcon Heavy launches - Wikipedia</title>\n"
     ]
    }
   ],
   "source": [
    "# Use soup.title attribute\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Imprimir el título de la página para verificar\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2: Extract all column/variable names from the HTML table header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to collect all relevant column names from the HTML table header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find all tables on the wiki page first. If you need to refresh your memory about `BeautifulSoup`, please check the external reference link towards the end of this lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título de la página: List of Falcon 9 and Falcon Heavy launches - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "# Crear un objeto BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Verificar el título de la página para asegurarnos de que se parseó correctamente\n",
    "print(\"Título de la página:\", soup.title.string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the third table is our target table contains the actual launch records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título de la página: List of Falcon 9 and Falcon Heavy launches - Wikipedia\n",
      "Nombres de las columnas: ['Date and time (UTC)', 'Version,booster[c]', 'Launch site', 'Payload[d]', 'Orbit', 'Customer']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la página de Wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches\"\n",
    "\n",
    "# Enviar una solicitud HTTP a la página\n",
    "response = requests.get(url)\n",
    "\n",
    "# Crear un objeto BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Verificar el título de la página\n",
    "print(\"Título de la página:\", soup.title.string)\n",
    "\n",
    "# Encontrar todas las tablas en la página\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Seleccionar la tercera tabla que contiene los registros de lanzamientos\n",
    "target_table = tables[2]\n",
    "\n",
    "# Extraer los nombres de las columnas de la tabla\n",
    "column_names = []\n",
    "for th in target_table.find_all('th'):\n",
    "    column_names.append(th.text.strip())\n",
    "\n",
    "# Mostrar los nombres de las columnas\n",
    "print(\"Nombres de las columnas:\", column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should able to see the columns names embedded in the table header elements `<th>` as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<tr>\n",
    "<th scope=\"col\">Flight No.\n",
    "</th>\n",
    "<th scope=\"col\">Date and<br/>time (<a href=\"/wiki/Coordinated_Universal_Time\" title=\"Coordinated Universal Time\">UTC</a>)\n",
    "</th>\n",
    "<th scope=\"col\"><a href=\"/wiki/List_of_Falcon_9_first-stage_boosters\" title=\"List of Falcon 9 first-stage boosters\">Version,<br/>Booster</a> <sup class=\"reference\" id=\"cite_ref-booster_11-0\"><a href=\"#cite_note-booster-11\">[b]</a></sup>\n",
    "</th>\n",
    "<th scope=\"col\">Launch site\n",
    "</th>\n",
    "<th scope=\"col\">Payload<sup class=\"reference\" id=\"cite_ref-Dragon_12-0\"><a href=\"#cite_note-Dragon-12\">[c]</a></sup>\n",
    "</th>\n",
    "<th scope=\"col\">Payload mass\n",
    "</th>\n",
    "<th scope=\"col\">Orbit\n",
    "</th>\n",
    "<th scope=\"col\">Customer\n",
    "</th>\n",
    "<th scope=\"col\">Launch<br/>outcome\n",
    "</th>\n",
    "<th scope=\"col\"><a href=\"/wiki/Falcon_9_first-stage_landing_tests\" title=\"Falcon 9 first-stage landing tests\">Booster<br/>landing</a>\n",
    "</th></tr>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to iterate through the `<th>` elements and apply the provided `extract_column_from_header()` to extract column name one by one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título de la página: List of Falcon 9 and Falcon Heavy launches - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "# Crear un objeto BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Verificar el título de la página\n",
    "print(\"Título de la página:\", soup.title.string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the extracted column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar todas las tablas en la página\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Seleccionar la tercera tabla que contiene los registros de lanzamientos\n",
    "target_table = tables[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombres de las columnas extraídas:\n",
      "['Date and time ( UTC )', 'Version, booster [c]', 'Launch site', 'Payload [d]', 'Orbit', 'Customer']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obtener todos los elementos <th> del documento HTML usando BeautifulSoup\n",
    "headers = target_table.find_all('th')\n",
    "\n",
    "# Lista para almacenar nombres de columna extraídos\n",
    "column_names = []\n",
    "\n",
    "# Función para extraer nombres de columna de un <th>\n",
    "def extract_column_from_header(header):\n",
    "    return header.get_text(separator=\" \", strip=True)\n",
    "\n",
    "# Iterar a través de cada elemento <th> y aplicar extract_column_from_header()\n",
    "for header in headers:\n",
    "    column_name = extract_column_from_header(header)\n",
    "    if column_name is not None and len(column_name) > 0:\n",
    "        column_names.append(column_name)\n",
    "\n",
    "# Imprimir los nombres de columna extraídos\n",
    "print(\"Nombres de las columnas extraídas:\")\n",
    "print(column_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Create a data frame by parsing the launch HTML tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an empty dictionary with keys from the extracted column names in the previous task. Later, this dictionary will be converted into a Pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['static_fire_date_utc', 'static_fire_date_unix', 'net', 'window',\n",
      "       'rocket', 'success', 'failures', 'details', 'crew', 'ships', 'capsules',\n",
      "       'payloads', 'launchpad', 'flight_number', 'name', 'date_utc',\n",
      "       'date_unix', 'date_local', 'date_precision', 'upcoming', 'cores',\n",
      "       'auto_update', 'tbd', 'launch_library_id', 'id', 'fairings.reused',\n",
      "       'fairings.recovery_attempt', 'fairings.recovered', 'fairings.ships',\n",
      "       'links.patch.small', 'links.patch.large', 'links.reddit.campaign',\n",
      "       'links.reddit.launch', 'links.reddit.media', 'links.reddit.recovery',\n",
      "       'links.flickr.small', 'links.flickr.original', 'links.presskit',\n",
      "       'links.webcast', 'links.youtube_id', 'links.article', 'links.wikipedia',\n",
      "       'fairings'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# URL de la API de SpaceX\n",
    "url_launches = 'https://api.spacexdata.com/v4/launches'\n",
    "\n",
    "# Realizar la solicitud GET\n",
    "response_launches = requests.get(url_launches)\n",
    "data_launches = response_launches.json()\n",
    "\n",
    "# Convertir la respuesta en un DataFrame\n",
    "df_launches = pd.json_normalize(data_launches)\n",
    "\n",
    "# Mostrar las columnas disponibles\n",
    "print(df_launches.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to fill up the `launch_dict` with launch records extracted from table rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, HTML tables in Wiki pages are likely to contain unexpected annotations and other types of noises, such as reference links `B0004.1[8]`, missing values `N/A [e]`, inconsistent formatting, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the parsing process, we have provided an incomplete code snippet below to help you to fill up the `launch_dict`. Please complete the following code snippet with TODOs or you can choose to write your own logic to parse all launch tables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lista de nombres de columnas extraídas en el paso anterior\n",
    "column_names = [\n",
    "    \"Flight No.\", \"Date\", \"Time\", \"Version Booster\", \"Launch site\", \n",
    "    \"Payload\", \"Payload mass\", \"Orbit\", \"Customer\", \"Launch outcome\", \n",
    "    \"Booster landing\"\n",
    "]\n",
    "\n",
    "# Crear un diccionario vacío con claves de los nombres de columnas\n",
    "launch_dict = {col: [] for col in column_names}\n",
    "\n",
    "# Función para extraer nombres de columna de un <th>\n",
    "def extract_column_from_header(header):\n",
    "    return header.get_text(separator=\" \", strip=True)\n",
    "\n",
    "# Iterar a través de las tablas relevantes\n",
    "for table in tables:\n",
    "    for row in table.find_all('tr'):\n",
    "        # Verificar si la primera celda es un número de vuelo y si tiene un elemento th\n",
    "        if row.th and row.th.string and row.th.string.strip().isdigit():\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) < 8:\n",
    "                continue\n",
    "\n",
    "            # Ejemplo de extracción de datos; ajustar según la estructura de la tabla\n",
    "            flight_number = row.th.text.strip()\n",
    "            date_time = cells[0].text.strip().split()\n",
    "            date = date_time[0] if len(date_time) > 0 else ''\n",
    "            time = date_time[1] if len(date_time) > 1 else ''\n",
    "            version_booster = cells[1].text.strip()\n",
    "            launch_site = cells[2].text.strip()\n",
    "            payload = cells[3].text.strip()\n",
    "            payload_mass = cells[4].text.strip()\n",
    "            orbit = cells[5].text.strip()\n",
    "            customer = cells[6].text.strip()\n",
    "            launch_outcome = cells[7].text.strip()\n",
    "            booster_landing = cells[8].text.strip() if len(cells) > 8 else ''\n",
    "\n",
    "            # Añadir los datos extraídos al diccionario\n",
    "            launch_dict['Flight No.'].append(flight_number)\n",
    "            launch_dict['Date'].append(date)\n",
    "            launch_dict['Time'].append(time)\n",
    "            launch_dict['Version Booster'].append(version_booster)\n",
    "            launch_dict['Launch site'].append(launch_site)\n",
    "            launch_dict['Payload'].append(payload)\n",
    "            launch_dict['Payload mass'].append(payload_mass)\n",
    "            launch_dict['Orbit'].append(orbit)\n",
    "            launch_dict['Customer'].append(customer)\n",
    "            launch_dict['Launch outcome'].append(launch_outcome)\n",
    "            launch_dict['Booster landing'].append(booster_landing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have fill in the parsed launch record values into `launch_dict`, you can create a dataframe from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exportado a spacex_web_scraped.csv\n",
      "  Flight No. Date     Time       Version Booster   Launch site  \\\n",
      "0        195    3  January  F9 B5 ♺ B1060.15[22]  CCSFS,SLC-40   \n",
      "1        196   10  January       F9 B5 ♺ B1076.2  CCSFS,SLC-40   \n",
      "2        197   18  January       F9 B5 ♺ B1077.2  CCSFS,SLC-40   \n",
      "3        198   19  January          F9 B5B1075.1   VSFB,SLC-4E   \n",
      "4        199   26  January        F9 B5 ♺B1067.9  CCSFS,SLC-40   \n",
      "\n",
      "                                             Payload  \\\n",
      "0   Transporter-6: (115 payloads Smallsat Rideshare)   \n",
      "1  OneWeb Flight #16 / SpaceX Flight 2[28][29] (4...   \n",
      "2      USA-343 / GPS III-06 (Amelia Earhart)[39][40]   \n",
      "3                 Starlink Group 2–4 (51 satellites)   \n",
      "4                 Starlink Group 5-2 (56 satellites)   \n",
      "\n",
      "                 Payload mass      Orbit  Customer Launch outcome  \\\n",
      "0                  Unknown[e]        SSO   Various        Success   \n",
      "1        6,000 kg (13,000 lb)  Polar LEO    OneWeb        Success   \n",
      "2         4,352 kg (9,595 lb)        MEO  USSF[41]        Success   \n",
      "3       15,000 kg (33,000 lb)        LEO    SpaceX        Success   \n",
      "4  ~17,400 kg (38,400 lb)[46]        LEO    SpaceX        Success   \n",
      "\n",
      "       Booster landing  \n",
      "0  Success(ground pad)  \n",
      "1  Success(ground pad)  \n",
      "2  Success(drone ship)  \n",
      "3  Success(drone ship)  \n",
      "4  Success(drone ship)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Asumiendo que launch_dict ya está lleno con los datos del lanzamiento\n",
    "\n",
    "# Crear un DataFrame desde el diccionario\n",
    "df = pd.DataFrame(launch_dict)\n",
    "\n",
    "# Exportar el DataFrame a CSV\n",
    "df.to_csv('spacex_web_scraped.csv', index=False)\n",
    "\n",
    "# Verificar que se haya exportado correctamente\n",
    "print(\"DataFrame exportado a spacex_web_scraped.csv\")\n",
    "# Crear un DataFrame desde el diccionario\n",
    "df = pd.DataFrame(launch_dict)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame para verificar\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export it to a <b>CSV</b> for the next section, but to make the answers consistent and in case you have difficulties finishing this lab. \n",
    "\n",
    "Following labs will be using a provided dataset to make each lab independent. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>df.to_csv('spacex_web_scraped.csv', index=False)</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exportado a spacex_web_scraped.csv\n"
     ]
    }
   ],
   "source": [
    "# Exportar el DataFrame a CSV\n",
    "df.to_csv('spacex_web_scraped.csv', index=False)\n",
    "\n",
    "# Verificar que se haya exportado correctamente\n",
    "print(\"DataFrame exportado a spacex_web_scraped.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>df.to_csv('spacex_web_scraped.csv', index=False)</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.linkedin.com/in/yan-luo-96288783/\">Yan Luo</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.linkedin.com/in/nayefaboutayoun/\">Nayef Abou Tayoun</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description      |\n",
    "| ----------------- | ------- | ---------- | ----------------------- |\n",
    "| 2021-06-09        | 1.0     | Yan Luo    | Tasks updates           |\n",
    "| 2020-11-10        | 1.0     | Nayef      | Created the initial version |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2021 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
